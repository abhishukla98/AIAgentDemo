{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1de16d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro API KEY Variable exists\n"
     ]
    }
   ],
   "source": [
    "from  langchain_openai import ChatOpenAI\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# This function will load all the variables from the .env file and will \n",
    "# make them available in the os.environ dictionary (env variables)\n",
    "load_dotenv() \n",
    "\n",
    "if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"Bro API KEY Variable exists\")\n",
    "else:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found\")\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from  langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser\n",
    "\n",
    "llm_openai = ChatOpenAI(model=\"gpt-5-mini\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3dffae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "class llm_schema(BaseModel):\n",
    "    movie_summary_flag: Literal[\"positive\", \"negative\"]\n",
    "\n",
    "llm_structured_output = llm_openai.with_structured_output(llm_schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9559e2",
   "metadata": {},
   "source": [
    "# **CHAIN WITH Conditional Chains**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73484c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK -1 [Prompt]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a movie review evaluator\"),\n",
    "    (\"human\", \"Please categorize the movie review as positive or negative : {input}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63f6c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK - 2 [LLM]\n",
    "\n",
    "llm_structured_output = llm_openai.with_structured_output(llm_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e74071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK - 3 [Custom Runnable]\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def pydantic_json(input:llm_schema)-> str:\n",
    "\n",
    "    return input.model_dump()['movie_summary_flag']\n",
    "\n",
    "pydantic_json_lambda = RunnableLambda(pydantic_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee255e31",
   "metadata": {},
   "source": [
    "### **Conditional Chain 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "432cde90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK - 1 [Prompt]\n",
    "\n",
    "linkedin_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a LinkedIn post generator\"),\n",
    "    (\"human\", \"Create a post for the following text for LinkedIn: {text}\")])\n",
    "\n",
    "# TASK - 2 [LLM]\n",
    "\n",
    "llm_openai = ChatOpenAI(model=\"gpt-5-mini\",temperature=0)\n",
    "\n",
    "# TASK - 3 [Str Parser]\n",
    "\n",
    "str_parser = StrOutputParser()\n",
    "\n",
    "chain_linkedin = linkedin_prompt | llm_openai | str_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316927eb",
   "metadata": {},
   "source": [
    "### **Conditional Chain 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5857d2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnableLambda, RunnableBranch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59a9c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insta_chain(text:dict):\n",
    "\n",
    "    text = text[\"text\"]\n",
    "\n",
    "    # TASK - 1 [Prompt]\n",
    "    insta_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a LinkedIn post generator\"),\n",
    "    (\"human\", \"Create a post for the following text for Instagram: {text}\")])\n",
    "    \n",
    "    # TASK - 2 [LLM]\n",
    "    llm_openai = ChatOpenAI(model=\"gpt-5-mini\",temperature=0)\n",
    "\n",
    "    # TASK - 3 [Str Parser]\n",
    "    str_parser = StrOutputParser()\n",
    "\n",
    "    chain_insta = insta_prompt | llm_openai | str_parser\n",
    "\n",
    "    result = chain_insta.invoke(text)\n",
    "\n",
    "    return result\n",
    "\n",
    "insta_chain_runnable = RunnableLambda(insta_chain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d735c3",
   "metadata": {},
   "source": [
    "### **Final Orchestration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3956fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_chain = RunnableBranch(\n",
    "    (lambda x: \"positive\" in x, chain_linkedin),\n",
    "     insta_chain_runnable\n",
    ")\n",
    "\n",
    "final_orchestrator = prompt_template | llm_structured_output | pydantic_json_lambda | conditional_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f075d1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Positivity isn't just a mood â€” it's a strategy. When we choose to focus on solutions, acknowledge small wins, and bring curiosity instead of judgment to setbacks, teams become more resilient and productive. \\n\\nToday I challenged myself to start meetings by sharing one recent win, however small. The shift in tone was immediate: people came in more engaged, ideas flowed more freely, and follow-ups actually happened. \\n\\nSmall consistent choices shape culture. What one positive habit could you start this week?\\n\\n#positivity #mindset #leadership #growth #wellbeing\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_orchestrator.invoke({\"input\": \"I loved this KGF movie\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
